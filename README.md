# A model based on RoBERTa for assigning VAD scores to sentences.

### *Editing...
I am currently developing this model for my graduation thesis, and I intend to continue this research as part of my future master's program and research.
This will be updated after I finish to write paper.

### DataSet
Emo Bank [An Analysis of Annotated Corpora for Emotion Classification in Text](https://aclanthology.org/C18-1179) (Bostan & Klinger, COLING 2018)

Sven Buechel and Udo Hahn. 2017. EmoBank: Studying the Impact of Annotation Perspective and Representation Format on Dimensional Emotion Analysis. In EACL 2017 - Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics. Valencia, Spain, April 3-7, 2017. Volume 2, Short Papers, pages 578-585. Available: http://aclweb.org/anthology/E17-2092

Sven Buechel and Udo Hahn. 2017. Readers vs. writers vs. texts: Coping with different perspectives of text understanding in emotion annotation. In LAW 2017 - Proceedings of the 11th Linguistic Annotation Workshop @ EACL 2017. Valencia, Spain, April 3, 2017, pages 1-12. Available: https://sigann.github.io/LAW-XI-2017/papers/LAW01.pdf

### Reference
Paul Ekman. An argument for basic emotions. Cognition and Emotion, 6(3-4):169–200, 1992.

Margaret M. Bradley and Peter J. Lang. Affective norms for english words (anew): Instruction
manual and affective ratings. In Technical Report
C-1. The Center for Research in Psychophysiology, University of Florida., 1999.

Agnes Moors, Jan De Houwer, Dirk Hermans,
Sabine Wanmaker, Kevin van Schie, Anne-Laura
Harmelen, Maarten De Schryver, Jeffrey Winne,
and Marc Brysbaert. Norms of valence, arousal,
dominance, and age of acquisition for 4,300 dutch
words. Behavior research methods, 09 2012.

Sven Buechel and Udo Hahn. EmoBank: Studying the impact of annotation perspective and representation format on dimensional emotion analysis. In Proceedings of the 15th Conference of the
European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers,
pages 578–585, Valencia, Spain, April 2017. Association for Computational Linguistics.

Jacob Devlin, Ming-Wei Chang, Kenton Lee,
and Kristina Toutanova. Bert: Pre-training of
deep bidirectional transformers for language understanding, 2019.

Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du,
Mandar Joshi, Danqi Chen, Omer Levy, Mike
Lewis, Luke Zettlemoyer, and Veselin Stoyanov.
Roberta: A robustly optimized bert pretraining
approach, 2019.

Diederik P. Kingma and Jimmy Ba. Adam: A
method for stochastic optimization, 2017.
